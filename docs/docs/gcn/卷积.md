# 卷积

如何充分的理解卷积？ [知乎卷积话题](https://www.zhihu.com/collection/496869355) 其中解释的最好的是 [palet的回答](https://www.zhihu.com/question/22298352/answer/637156871)

## 卷积的公式

$$
(f \star g) (n) = \int_{-\infty}^{+\infty} f(t)g(n-t)dt
$$

如何通俗易懂的理解这个公式呢？[palet的回答](https://www.zhihu.com/question/22298352/answer/637156871) 下面是对这个回答的自我总结。


对于 $g(n-t)$ 可以看做是 $g(t)$ 经过变换后的结果:

1. $g(-t) \rightarrow g(t)$: 相当于对 $y$ 轴进行了翻转
2. $g(n-t) \rightarrow g(-t)$: 相当于$g(-t)$向左平移 $n$ 个单位.

所以卷积的公式是计算 $f(t)$ 与 经过 **翻转** 再 **向左平移 $n$ ** 个单位的 **乘积** **累加** 的结果。

那么 $g(t)$ 经过这么一番操作究竟是为了做什么? 通过下面的例子来介绍。

## 一维卷积举例

假设 $f(t)$ 表示的是 $t$ 时刻发生的信号, $g(t)$ 是一个信号从产生经过 $t$ 时间单位后的衰减系数。 注意 $f(t)$ 和 $g(t)$ 的 $t$ 是不同的含义。 例如: $f(1)$ 表示 $1$ 时刻发生的信号, $g(1)$ 表示经过 $1$ 时间单位后衰减的结果，显然 $g(0)$ 是最大的, 因为 $g(0)$ 表示的是没有衰减。那么，看看在第5个时刻，$f(1)$ 表示 $1$ 时刻发生的信号, 在第 $5$ 时刻的信号衰减因子 $g(4)$(因为 从 $1$ 时刻发生，要经历 $4=5-1$ 时间衰减), 第5时刻的信号强度就是 $h(5) = f(1)*g(4) = f(1) * g(5-1)$. 整理下就是 $h(n) = f(t)*g(n-t)$, 这个公式表示的含义就是: 从 $t$ 时刻发生的信号, 经过了 $n-t$ 个时间单位后的衰减系数是 $g(n-t)$, $n$ 时刻的信号强度就是 $h(n)$.

![卷积示意图](https://upload-images.jianshu.io/upload_images/1809271-d1b5c53c0fe1b83d.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)


当计算 $n=4$ 的时候，$f(t)$ 从 $1$, $2$, $3$ 三个时刻发出了信号，$g(t)$ 表示经过了几个时间单位，分别结果了 $3$, $2$, $1$ 个时间单位, 所以有, 当 $n=4$时刻的信号强度是将前面所有的信号加起来, 所以有 

$$
H(n) = (f \star g) (n) = \sum_{t=1}^{3} {f(t)*g(n-t)}
$$

写成积分的形式就是

$$
H(n) = (f \star g) (n) = \int_{-\infty}^{+\infty} f(t)g(n-t)dt
$$

## 图像卷积举例

前面的卷积是一个参数的卷积而对于图像来说是空间上针对每一个点处的卷积，所以定义上就是二维的 

$$
H(u,v)= \int_{-\infty}^{+\infty} {f(x, y)*g(u-x, v-y)} dxdy
$$

对于图像来说是离散的表达方式。由于 $g(x,y)$ 是一个矩阵，比如 $3 \times 3$的矩阵, 那么对于 $g(u-x, v-y)$ 来说经过: 1. 沿$x,y$翻转，后再向左平移 $u, v$ 个单位. 因为 $g(x,y)$ 是 $3 \times 3$的矩阵, 所以 $-1 \le u-x \le +1 \rightarrow (u-1) \le x \le (u+1)$, 所以对于 $f(x,y)$ 来说，仅仅计算的是也是 $3 \times 3$ 那一小块方阵。看看具体的例子:

$(u,v)=(5, 6), (x,y)=(4,5)$ 那么就有 $h(u,v)=h(5,6)=f(4,5)*g(1,1)$. 全部写下来就是:

$$
H(5,6) 
= \sum_{x=-\infty,y=-\infty}^{+\infty,+\infty} {f(x,y)*g(5-x,6-y)} 
= \sum_{x=4,y=5}^{6,7} {f(x,y)*g(5-x,6-y)} 
$$

很明确，但是回想在深度学习中的CNN，貌似没有进行翻转和平移？那是因为，在深度学习中 实际上是 $g^{'}$ 是 $g$ 经过翻转后的结果, 所以将 $g$ 作为权重参数和直接使用 $g^{'}$ 也就是 翻转后的结果是一回事，没有什么区别，为了简单就直接使用了 $g^{'}$, 而实际上我们应该知道 $g^{'}$ 是 $g$ 翻转后的结果，这一本质。