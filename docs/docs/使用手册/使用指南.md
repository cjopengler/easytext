# 使用预训练词向量进行 fine-tuning 或者 freeze 训练

1. 继承 PretrainedVocabulary， 重写 load 方法, 来载入词向量。也可以使用默认的
载入方式，这里包括 Glovle6B 等词向量。
2. 在模型中使用 `torch.nn.Embedding.from_pretrained` 来载入 `PretrainedVocabulary.embedding_matrix`

下面说明在 freeze 以及 fine-tuning 两种模式下的设置:


## Freeze 模式

在 `OptimizerFactory` 需要将 embedding 参数  
`embedding.weight.requires_grad = False`, 同时在 optimizer 中，
将该参数剔除掉。其实在 optimizer 中不剔除也没关系，剔除是表示严谨。

## Fine-tuning 模式

在 `OptimizerFactory` 需要将 embedding 参数  
`embedding.weight.requires_grad = True`, 同时在 optimizer 中，
针对其学习率设置一个较小的值，因为仅仅是微调，与其他不同。